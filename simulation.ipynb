{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation studies\n",
    "\n",
    "(Move this notebook to the root directory to run it)\n",
    "\n",
    "Note: For all these studies, the hyperparameter search has already been completed."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pickle\n",
    "import argparse\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "from coxkan import CoxKAN\n",
    "from coxkan.utils import bootstrap_metric, set_seed\n",
    "\n",
    "SEED = set_seed(42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "### Reusable functions for the notebook\n",
    "\n",
    "def true_cindex(df):\n",
    "    global sim_config, duration_col, event_col, covariates\n",
    "    lph = sim_config['log_partial_hazard'](**df[covariates])\n",
    "    return concordance_index(df[duration_col], -lph, df[event_col])\n",
    "\n",
    "def cph_cindex(df):\n",
    "    global cph\n",
    "    return cph.score(df, scoring_method='concordance_index')\n",
    "\n",
    "def cph_reg_cindex(df):\n",
    "    global cph_reg\n",
    "    return cph_reg.score(df, scoring_method='concordance_index')\n",
    "\n",
    "def cph_formula(cph):\n",
    "    coefficients = cph.params_\n",
    "    terms = []\n",
    "    for covariate, coefficient in coefficients.items():\n",
    "        term = f\"{coefficient:.4f} * {covariate}\"\n",
    "        terms.append(term)\n",
    "    expression = \" + \".join(terms)\n",
    "    return expression\n",
    "\n",
    "def plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals):\n",
    "    #plot residuals in 1x2 grid vs x1 and x2\n",
    "    residuals = test_lph_vals - pred_lph_vals\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    axes[0].scatter(x1_vals, residuals, alpha=0.5)\n",
    "    #insert correlation as text\n",
    "    corr = np.corrcoef(x1_vals, residuals)[0, 1]\n",
    "    axes[0].text(0.5, 0.9, f'Correlation: {corr:.2f}', transform=axes[0].transAxes, fontsize=14)\n",
    "    axes[0].set_xlabel(r'$x_1$', fontsize=14)\n",
    "    axes[0].set_ylabel('Residuals', fontsize=14)\n",
    "    axes[0].set_title('Residuals vs $x_1$', fontsize=14)\n",
    "    axes[1].scatter(x2_vals, residuals, alpha=0.5)\n",
    "    #insert correlation as text\n",
    "    corr = np.corrcoef(x2_vals, residuals)[0, 1]\n",
    "    axes[1].text(0.5, 0.9, f'Correlation: {corr:.2f}', transform=axes[1].transAxes, fontsize=14)\n",
    "    axes[1].set_xlabel(r'$x_2$', fontsize=14)\n",
    "    axes[1].set_ylabel('Residuals', fontsize=14)\n",
    "    axes[1].set_title('Residuals vs $x_2$', fontsize=14)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return fig\n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian\n",
    "\n",
    "For our first study, we set the log-partial hazard to be a Gaussian:\n",
    "\n",
    "$$\\theta(\\mathbf{x}) = 5 \\exp(-2 (x_1^2 + x_2^2))$$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_name = \"sim_gaussian\"\n",
    "sim_name = \"gaussian\"\n",
    "\n",
    "### load configs\n",
    "with open(f'./configs/simulation/{sim_name}.yml', 'r') as file:\n",
    "    sim_config = yaml.safe_load(file)\n",
    "    sim_config['true_expr'] =  sim_config['log_partial_hazard'].split(': ')[-1] # log partial hazard expression\n",
    "    sim_config['log_partial_hazard'] = eval(sim_config['log_partial_hazard']) # convert to function\n",
    "\n",
    "# (config from hyperparameter search)\n",
    "with open(f'configs/coxkan/{exp_name}.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# data already generated (from sweep.py)\n",
    "df_train = pd.read_csv(f'./data/{exp_name}_train.csv')\n",
    "df_test = pd.read_csv(f'./data/{exp_name}_test.csv')\n",
    "duration_col, event_col, covariates = 'duration', 'event', df_train.columns[:-2]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate performance of the 'true' expression. Clearly, the C-Index will not be perfect since survival time is randomly distributed."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# C-Index of true log partial hazard expression\n",
    "cindex_true = bootstrap_metric(true_cindex, df_test, N=100)['formatted']\n",
    "\n",
    "print(f\"True log partial hazard: {sim_config['true_expr']}\")\n",
    "print(f\"True C-Index: {cindex_true}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Cox Proportional Hazards Model:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# CoxPH\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df_train, duration_col=duration_col, event_col=event_col)\n",
    "cindex_cph = bootstrap_metric(cph_cindex, df_test, N=100)['formatted']\n",
    "formula_cph = cph_formula(cph)\n",
    "print(f\"CoxPH Expression: {formula_cph}\")\n",
    "print(f\"CoxPH C-Index: {cindex_cph}\")\n",
    "\n",
    "#plot residuals\n",
    "x1_vals = df_test['x1'].values\n",
    "x2_vals = df_test['x2'].values\n",
    "test_lph_vals = sim_config['log_partial_hazard'](x1_vals, x2_vals, *df_test[covariates[2:]].values.T)\n",
    "pred_lph_vals = cph.predict_partial_hazard(df_test)\n",
    "\n",
    "fig = plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals)\n",
    "\n",
    "# do same for CoxPH with regularization\n",
    "cph_reg = CoxPHFitter(penalizer=0.5, l1_ratio=1)\n",
    "cph_reg.fit(df_train, duration_col=duration_col, event_col=event_col)\n",
    "cindex_cph_reg = bootstrap_metric(cph_reg_cindex, df_test, N=100)['formatted']\n",
    "formula_cph_reg = cph_formula(cph_reg)\n",
    "print(f\"CoxPH (Reg) Expression: {formula_cph_reg}\")\n",
    "print(f\"CoxPH (Reg) C-Index: {cindex_cph_reg}\")\n",
    "#plot residuals\n",
    "x1_vals = df_test['x1'].values\n",
    "x2_vals = df_test['x2'].values\n",
    "test_lph_vals = sim_config['log_partial_hazard'](x1_vals, x2_vals, *df_test[covariates[2:]].values.T)\n",
    "pred_lph_vals = cph_reg.predict_partial_hazard(df_test)\n",
    "fig = plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train DeepSurv on same task\n",
    "import torchtuples as tt\n",
    "from coxkan.utils import FastCoxLoss, count_parameters, bootstrap_metric, set_seed, SYMBOLIC_LIB\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open(f'configs/mlp/sim_gaussian.yml', 'r') as f:\n",
    "    mlp_config = yaml.safe_load(f)\n",
    "    \n",
    "mlp = tt.practical.MLPVanilla(\n",
    "    in_features=len(covariates), out_features=1, output_bias=False, **mlp_config['init_params']\n",
    ")\n",
    "optimizer = tt.optim.Adam(**mlp_config['optimizer_params'])\n",
    "deepsurv = tt.Model(mlp, loss=FastCoxLoss, optimizer=optimizer)\n",
    "deepsurv_params = count_parameters(mlp)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_test = torch.tensor(df_test[covariates].values).double()\n",
    "y_test = torch.tensor(df_test[[duration_col, event_col]].values).double()\n",
    "\n",
    "def mlp_cindex(df):\n",
    "    lph = deepsurv.predict(torch.tensor(df[covariates].values).double())\n",
    "    return concordance_index(df[duration_col], -lph, df[event_col])\n",
    "\n",
    "def mlp_cindex_metric_fn(lph, labels):\n",
    "    return concordance_index(labels[:, 0].detach().numpy(), -lph.detach().numpy(), labels[:, 1].detach().numpy())\n",
    "\n",
    "# Training\n",
    "if mlp_config['early_stopping']:\n",
    "    train, val = train_test_split(df_train, test_size=0.2, random_state=42, stratify=df_train['event'])\n",
    "    X_val = torch.tensor(val[covariates].values).double()\n",
    "    y_val = torch.tensor(val[[duration_col, event_col]].values).double()\n",
    "    X_train = torch.tensor(train[covariates].values).double()\n",
    "    y_train = torch.tensor(train[[duration_col, event_col]].values).double()\n",
    "    log = deepsurv.fit(\n",
    "        X_train, y_train, batch_size=len(X_train), val_data=(X_val, y_val), epochs=mlp_config['epochs'], verbose=False,\n",
    "        metrics={'cindex': mlp_cindex_metric_fn}, callbacks=[tt.callbacks.EarlyStopping(patience=20)]\n",
    "    )\n",
    "else:\n",
    "    X_train = torch.tensor(df_train[covariates].values).double()\n",
    "    y_train = torch.tensor(df_train[[duration_col, event_col]].values).double()\n",
    "    log = deepsurv.fit(\n",
    "        X_train, y_train, batch_size=len(X_train), val_data=(X_test, y_test), epochs=mlp_config['epochs'], verbose=False,\n",
    "        metrics={'cindex': mlp_cindex_metric_fn}\n",
    "    )\n",
    "\n",
    "cindex_mlp = bootstrap_metric(mlp_cindex, df_test, N=100)['formatted']\n",
    "print(f\"MLP C-Index: {cindex_mlp}\")\n",
    "\n",
    "#plot residuals\n",
    "x1_vals = X_test[:, 0].numpy()\n",
    "x2_vals = X_test[:, 1].numpy()\n",
    "test_lph_vals = sim_config['log_partial_hazard'](x1_vals, x2_vals, *df_test[covariates[2:]].values.T)\n",
    "pred_lph_vals = deepsurv.predict(X_test).squeeze().detach().cpu().numpy()\n",
    "fig = plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#train SuMo-net\n",
    "from sumo import sumo\n",
    "from lifelines.utils import concordance_index\n",
    "\n",
    "print(dir(sumo))\n",
    "\n",
    "with open(f'configs/mlp/sim_gaussian.yml', 'r') as f:\n",
    "    mlp_config = yaml.safe_load(f)\n",
    "    \n",
    "print(mlp_config)\n",
    "    \n",
    "lr = mlp_config['optimizer_params']['lr']\n",
    "weight_decay = mlp_config['optimizer_params']['weight_decay']\n",
    "num_nodes = mlp_config['init_params']['num_nodes']\n",
    "dropout = mlp_config['init_params']['dropout']\n",
    "\n",
    "model = sumo.SuMo(layers = num_nodes, dropout = dropout)\n",
    "X= df_train[covariates].values\n",
    "e = df_train['event'].values\n",
    "t = df_train['duration'].values\n",
    "\n",
    "#print min and max of e and t\n",
    "print(f\"Min event: {e.min()}, Max event: {e.max()}\")\n",
    "print(f\"Min duration: {t.min()}, Max duration: {t.max()}\")\n",
    "model = model.fit(X,t,e,random_state=42, n_iter=1000, lr=lr, weight_decay=weight_decay)\n",
    "                  \n",
    "\n",
    "X_test = df_test[covariates].values\n",
    "e_test = df_test['event'].values\n",
    "t_test = df_test['duration'].values\n",
    "# convert to torch tensors\n",
    "X_test = torch.tensor(X_test).double()\n",
    "t_test = torch.tensor(t_test).double()\n",
    "e_test = torch.tensor(e_test).double()\n",
    "print(X_test.shape, t_test.shape, e_test.shape)\n",
    "survival, intensity = model.forward(X_test, t_test, gradient = False)\n",
    "survival = survival.detach().numpy()\n",
    "\n",
    "# calculate concordance between predicted survival and t_test\n",
    "survival = survival\n",
    "\n",
    "cindex_sumo = concordance_index(t_test, -survival, e_test)\n",
    "\n",
    "# calculate concordance between\n",
    "print(survival.shape,survival.max(), survival.min())\n",
    "print(survival)\n",
    "print(f\"SuMo C-Index: {cindex_sumo}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate CoxKAN:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "assert False\n",
    "# CoxKAN\n",
    "ckan = CoxKAN(seed=42, **config['init_params'])\n",
    "\n",
    "log = ckan.train(df_train, df_test, duration_col, event_col, **config['train_params'])\n",
    "\n",
    "cindex_pre = bootstrap_metric(ckan.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Pre-symbolic: {cindex_pre}\")\n",
    "\n",
    "# Save\n",
    "ckan.save_ckpt(f'checkpoints/{exp_name}/model.pt')\n",
    "fig = log.plot()\n",
    "fig.savefig(f'checkpoints/{exp_name}/evolution.png')\n",
    "fig = ckan.plot(beta=40, in_vars=[r'$x_1$', r'$x_2$', r'$\\epsilon_1$', r'$\\epsilon_2$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_pre.png', dpi=600)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Pruning\n",
    "ckan = ckan.prune_nodes(config['prune_threshold'])\n",
    "ckan.prune_edges(config['prune_threshold'], verbose=True)\n",
    "fig = ckan.plot(beta=40, in_vars=[r'$x_1$', r'$x_2$', r'$\\epsilon_1$', r'$\\epsilon_2$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_pruned.png', dpi=600)\n",
    "cindex_pruned = bootstrap_metric(ckan.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Pruned: {cindex_pruned}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can recognise these activation functions as `x^2, x^2, exp`. We try fitting these functions:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "r2 = ckan.fix_symbolic(0, 0, 0, 'x^2', verbose=False)\n",
    "print(f\"Activation (0,0,0): x^2 fits with R^2: {r2}\")\n",
    "r2 = ckan.fix_symbolic(0, 1, 0, 'x^2', verbose=False)\n",
    "print(f\"Activation (0,1,0): x^2 fits with R^2: {r2}\")\n",
    "r2 = ckan.fix_symbolic(1, 0, 0, 'exp', verbose=False)\n",
    "print(f\"Activation (1,0,0): exp fits with R^2: {r2}\")\n",
    "\n",
    "formula = ckan.symbolic_formula()[0][0]\n",
    "formula"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high $R^2$ values (coefficient of determination) verify that the true expression was learnt. However, the affine parameters are not quite correct (although a close approximation). We finish by training the affine params:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ckan.train(df_train, df_test, duration_col, event_col, opt=\"LBFGS\", steps=50)\n",
    "formula = ckan.symbolic_formula()[0][0]\n",
    "print(formula)\n",
    "\n",
    "#plot residuals in ckan\n",
    "x1_vals = df_test['x1'].values\n",
    "x2_vals = df_test['x2'].values\n",
    "test_lph_vals = sim_config['log_partial_hazard'](x1_vals, x2_vals, *df_test[covariates[2:]].values.T)\n",
    "pred_lph_vals = ckan.predict(df_test)\n",
    "\n",
    "fig = plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the result is near-perfect. Now we just save the results/visualisations:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig = ckan.plot(beta=40, in_vars=[r'$x_1$', r'$x_2$', r'$\\epsilon_1$', r'$\\epsilon_2$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_symbolic.png', dpi=600)\n",
    "cindex_symbolic = bootstrap_metric(ckan.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Symbolic: {cindex_symbolic}\")\n",
    "\n",
    "results = {\n",
    "    'cindex_true': cindex_true,\n",
    "    'cindex_cph': cindex_cph,\n",
    "    'cindex_pre': cindex_pre,\n",
    "    'cindex_pruned': cindex_pruned,\n",
    "    'cindex_symbolic': cindex_symbolic,\n",
    "    'coxkan_formula': formula,\n",
    "    'coxph_formula': formula_cph,\n",
    "}\n",
    "\n",
    "with open(f'checkpoints/{exp_name}/results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shallow\n",
    "\n",
    "In survival analysis, it is common that we encounter covariates that satisfy the linear Cox Proportional Hazards model after some non-linear transformation. In other words, they have non-linear relationships to the patient's risk but they do not interact. To simulate this situation we use the following expression for the log-partial hazard:\n",
    "\n",
    "$$\\theta(\\mathbf{x}) = \\tanh(5x_1) + \\sin(2\\pi x_2) + x_3^2$$\n",
    "\n",
    "This can be captured by a shallow KAN (no hidden layers)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_name = \"sim_depth_1\"\n",
    "sim_name = \"depth_1\"\n",
    "\n",
    "### load configs\n",
    "with open(f'./configs/simulation/{sim_name}.yml', 'r') as file:\n",
    "    sim_config = yaml.safe_load(file)\n",
    "    sim_config['true_expr'] =  sim_config['log_partial_hazard'].split(': ')[-1] # log partial hazard expression\n",
    "    sim_config['log_partial_hazard'] = eval(sim_config['log_partial_hazard']) # convert to function\n",
    "\n",
    "# (config from hyperparameter search)\n",
    "with open(f'configs/coxkan/{exp_name}.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# data already generated (from sweep.py)\n",
    "df_train = pd.read_csv(f'./data/{exp_name}_train.csv')\n",
    "df_test = pd.read_csv(f'./data/{exp_name}_test.csv')\n",
    "duration_col, event_col, covariates = 'duration', 'event', df_train.columns[:-2]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate true expression:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# C-Index of true log partial hazard expression\n",
    "cindex_true = bootstrap_metric(true_cindex, df_test, N=100)['formatted']\n",
    "\n",
    "print(f\"True log partial hazard: {sim_config['true_expr']}\")\n",
    "print(f\"True C-Index: {cindex_true}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Cox proportional hazards model:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# CoxPH\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df_train, duration_col=duration_col, event_col=event_col)\n",
    "cindex_cph = bootstrap_metric(cph_cindex, df_test, N=100)['formatted']\n",
    "formula_cph = cph_formula(cph)\n",
    "print(f\"CoxPH Expression: {formula_cph}\")\n",
    "print(f\"CoxPH C-Index: {cindex_cph}\")\n",
    "\n",
    "#plot residuals\n",
    "x1_vals = df_test['x1'].values\n",
    "x2_vals = df_test['x2'].values\n",
    "test_lph_vals = sim_config['log_partial_hazard'](x1_vals, x2_vals, *df_test[covariates[2:]].values.T)\n",
    "pred_lph_vals = cph.predict_partial_hazard(df_test)\n",
    "fig = plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals)\n",
    "\n",
    "#do same but with regularisation\n",
    "cph = CoxPHFitter(penalizer=0.5, l1_ratio=1)\n",
    "cph.fit(df_train, duration_col=duration_col, event_col=event_col)\n",
    "cindex_cph = bootstrap_metric(cph_cindex, df_test, N=100)['formatted']\n",
    "formula_cph = cph_formula(cph)\n",
    "print(f\"CoxPH Expression: {formula_cph}\")\n",
    "print(f\"CoxPH C-Index: {cindex_cph}\")\n",
    "#plot residuals\n",
    "test_lph_vals = sim_config['log_partial_hazard'](x1_vals, x2_vals, *df_test[covariates[2:]].values.T)\n",
    "pred_lph_vals = cph.predict_partial_hazard(df_test)\n",
    "fig = plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train DeepSurv on same task\n",
    "import torchtuples as tt\n",
    "from coxkan.utils import FastCoxLoss, count_parameters, bootstrap_metric, set_seed, SYMBOLIC_LIB\n",
    "import torch\n",
    "\n",
    "with open(f'configs/mlp/sim_depth_1.yml', 'r') as f:\n",
    "    mlp_config = yaml.safe_load(f)\n",
    "mlp = tt.practical.MLPVanilla(\n",
    "    in_features=len(covariates), out_features=1, output_bias=False, **mlp_config['init_params']\n",
    ")\n",
    "optimizer = tt.optim.Adam(**mlp_config['optimizer_params'])\n",
    "deepsurv = tt.Model(mlp, loss=FastCoxLoss, optimizer=optimizer)\n",
    "deepsurv_params = count_parameters(mlp)\n",
    "# Convert to PyTorch tensors\n",
    "X_test = torch.tensor(df_test[covariates].values).double()\n",
    "y_test = torch.tensor(df_test[[duration_col, event_col]].values).double()\n",
    "\n",
    "# Training\n",
    "if mlp_config['early_stopping']:\n",
    "    train, val = train_test_split(df_train, test_size=0.2, random_state=42, stratify=df_train['event'])\n",
    "    X_val = torch.tensor(val[covariates].values).double()\n",
    "    y_val = torch.tensor(val[[duration_col, event_col]].values).double()\n",
    "    X_train = torch.tensor(train[covariates].values).double()\n",
    "    y_train = torch.tensor(train[[duration_col, event_col]].values).double()\n",
    "    log = deepsurv.fit(\n",
    "        X_train, y_train, batch_size=len(X_train), val_data=(X_val, y_val), epochs=mlp_config['epochs'], verbose=False,\n",
    "        metrics={'cindex': mlp_cindex_metric_fn}, callbacks=[tt.callbacks.EarlyStopping(patience=20)]\n",
    "    )\n",
    "else:\n",
    "    X_train = torch.tensor(df_train[covariates].values).double()\n",
    "    y_train = torch.tensor(df_train[[duration_col, event_col]].values).double()\n",
    "    log = deepsurv.fit(\n",
    "        X_train, y_train, batch_size=len(X_train), val_data=(X_test, y_test), epochs=mlp_config['epochs'], verbose=False,\n",
    "        metrics={'cindex': mlp_cindex_metric_fn}\n",
    "    )\n",
    "    \n",
    "cindex_mlp = bootstrap_metric(mlp_cindex, df_test, N=100)['formatted']\n",
    "print(f\"MLP C-Index: {cindex_mlp}\")\n",
    "#plot residuals\n",
    "x1_vals = X_test[:, 0].numpy()\n",
    "x2_vals = X_test[:, 1].numpy()\n",
    "test_lph_vals = sim_config['log_partial_hazard'](x1_vals, x2_vals, *df_test[covariates[2:]].values.T)\n",
    "pred_lph_vals = deepsurv.predict(X_test).squeeze().detach().cpu().numpy()\n",
    "fig = plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CoxKAN:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# CoxKAN\n",
    "ckan = CoxKAN(seed=42, **config['init_params'])\n",
    "\n",
    "log = ckan.train(df_train, df_test, duration_col, event_col, **config['train_params'])\n",
    "\n",
    "cindex_pre = bootstrap_metric(ckan.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Pre-symbolic: {cindex_pre}\")\n",
    "\n",
    "# Save\n",
    "ckan.save_ckpt(f'checkpoints/{exp_name}/model.pt')\n",
    "fig = log.plot()\n",
    "fig.savefig(f'checkpoints/{exp_name}/evolution.png', bbox_inches='tight')\n",
    "fig = ckan.plot(beta=10, in_vars=[r'$x_1$', r'$x_2$', r'$x_3$',r'$\\epsilon_1$', r'$\\epsilon_2$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_pre.png', bbox_inches='tight')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Pruning\n",
    "ckan = ckan.prune_nodes(config['prune_threshold'])\n",
    "ckan.prune_edges(config['prune_threshold'], verbose=True)\n",
    "fig = ckan.plot(beta=10, in_vars=[r'$x_1$', r'$x_2$', r'$x_3$',r'$\\epsilon_1$', r'$\\epsilon_2$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_pruned.png', bbox_inches='tight')\n",
    "cindex_pruned = bootstrap_metric(ckan.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Pruned: {cindex_pruned}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again recognise these activations: \n",
    "- some s-shaped function like `tanh` or `sigmoid`\n",
    "- some oscillating function like `sin` (or `cos` but this is just a matter of affine parameters)\n",
    "- a quadratic `x^2`\n",
    "\n",
    "In the case of the s-shaped function we try out both options and see which is better:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "_ = ckan.predict(df_test)\n",
    "fn, _, r2 = ckan.suggest_symbolic(0, 0, 0, lib=['tanh', 'sigmoid'], verbose=False)\n",
    "print(f\"Best: {fn} fits with R^2: {r2}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "r2 = ckan.fix_symbolic(0, 0, 0, 'tanh', verbose=False)\n",
    "print(f\"Activation (0,0,0): tanh fits with R^2: {r2}\")\n",
    "r2 = ckan.fix_symbolic(0, 1, 0, 'sin', verbose=False)\n",
    "print(f\"Activation (0,1,0): sin fits with R^2: {r2}\")\n",
    "r2 = ckan.fix_symbolic(0, 2, 0, 'x^2', verbose=False)\n",
    "print(f\"Activation (0,2,0): x^2 fits with R^2: {r2}\")\n",
    "\n",
    "formula = ckan.symbolic_formula()[0][0]\n",
    "print(formula)\n",
    "\n",
    "#plot residuals in ckan\n",
    "x1_vals = df_test['x1'].values\n",
    "x2_vals = df_test['x2'].values\n",
    "test_lph_vals = sim_config['log_partial_hazard'](x1_vals, x2_vals, *df_test[covariates[2:]].values.T)\n",
    "pred_lph_vals = ckan.predict(df_test)\n",
    "fig = plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high $R^2$ values (coefficient of determination) verify that the true expression was learnt. On first glance, the `sin` term appears incorrect, but note that: $ - 0.96 \\sin(6.27x + 12.58) \\approx -\\sin(2\\pi x - 3\\pi) = \\sin(2\\pi x)$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "_ = ckan.predict(df_test)\n",
    "fig = ckan.plot(beta=10, in_vars=[r'$x_1$', r'$x_2$', r'$x_3$',r'$\\epsilon_1$', r'$\\epsilon_2$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_symbolic.png', bbox_inches='tight')\n",
    "cindex_symbolic = bootstrap_metric(ckan.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Symbolic: {cindex_symbolic}\")\n",
    "\n",
    "results = {\n",
    "    'cindex_true': cindex_true,\n",
    "    'cindex_cph': cindex_cph,\n",
    "    'cindex_pre': cindex_pre,\n",
    "    'cindex_pruned': cindex_pruned,\n",
    "    'cindex_symbolic': cindex_symbolic,\n",
    "    'coxkan_formula': formula,\n",
    "    'coxph_formula': formula_cph,\n",
    "}\n",
    "\n",
    "with open(f'checkpoints/{exp_name}/results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this case, training the affine parameters doesnt yield a better expression:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "ckan.train(df_train, df_test, duration_col, event_col, opt=\"LBFGS\", steps=50)\n",
    "formula = ckan.symbolic_formula()[0][0]\n",
    "formula"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is likely due to the noise in the dataset - we can only get an approximation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep\n",
    "\n",
    "To contrast with the previous example, we now try an expression for the log-partial hazard that requires a deep KAN (2 hidden layers) to capture:\n",
    "\n",
    "$$\\theta(\\mathbf{x}) = 2\\sqrt{(x_1-x_2)^2 + (x_3-x_4)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_name = \"sim_deep\"\n",
    "sim_name = \"deep\"\n",
    "\n",
    "# load configs\n",
    "with open(f'./configs/simulation/{sim_name}.yml', 'r') as file:\n",
    "    sim_config = yaml.safe_load(file)\n",
    "    sim_config['true_expr'] =  sim_config['log_partial_hazard'].split(': ')[-1] # log partial hazard expression\n",
    "    sim_config['log_partial_hazard'] = eval(sim_config['log_partial_hazard']) # convert to function\n",
    "\n",
    "with open(f'configs/coxkan/{exp_name}.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# data already generated (from sweep.py)\n",
    "df_train = pd.read_csv(f'./data/{exp_name}_train.csv')\n",
    "df_test = pd.read_csv(f'./data/{exp_name}_test.csv')\n",
    "duration_col, event_col, covariates = 'duration', 'event', df_train.columns[:-2]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# C-Index of true log partial hazard expression\n",
    "cindex_true = bootstrap_metric(true_cindex, df_test, N=100)['formatted']\n",
    "\n",
    "print(f\"True log partial hazard: {sim_config['true_expr']}\")\n",
    "print(f\"True C-Index: {cindex_true}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# CoxPH\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df_train, duration_col=duration_col, event_col=event_col)\n",
    "cindex_cph = bootstrap_metric(cph_cindex, df_test, N=100)['formatted']\n",
    "formula_cph = cph_formula(cph)\n",
    "print(f\"CoxPH Expression: {formula_cph}\")\n",
    "print(f\"CoxPH C-Index: {cindex_cph}\")\n",
    "\n",
    "#plot residuals\n",
    "x1_vals = df_test['x1'].values\n",
    "x2_vals = df_test['x2'].values\n",
    "test_lph_vals = sim_config['log_partial_hazard'](x1_vals, x2_vals, *df_test[covariates[2:]].values.T)\n",
    "pred_lph_vals = cph.predict_partial_hazard(df_test)\n",
    "fig = plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals)\n",
    "\n",
    "# do same for CoxPH with regularization\n",
    "cph_reg = CoxPHFitter(penalizer=0.5, l1_ratio=1)\n",
    "cph_reg.fit(df_train, duration_col=duration_col, event_col=event_col)\n",
    "cindex_cph_reg = bootstrap_metric(cph_reg_cindex, df_test, N=100)['formatted']\n",
    "formula_cph_reg = cph_formula(cph_reg)\n",
    "print(f\"CoxPH (Reg) Expression: {formula_cph_reg}\")\n",
    "print(f\"CoxPH (Reg) C-Index: {cindex_cph_reg}\")\n",
    "#plot residuals\n",
    "test_lph_vals = sim_config['log_partial_hazard'](x1_vals, x2_vals, *df_test[covariates[2:]].values.T)\n",
    "pred_lph_vals = cph_reg.predict_partial_hazard(df_test)\n",
    "fig = plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train DeepSurv on same task\n",
    "import torchtuples as tt\n",
    "from coxkan.utils import FastCoxLoss, count_parameters, bootstrap_metric, set_seed, SYMBOLIC_LIB\n",
    "import torch\n",
    "\n",
    "with open(f'configs/mlp/sim_deep.yml', 'r') as f:\n",
    "    mlp_config = yaml.safe_load(f)\n",
    "mlp = tt.practical.MLPVanilla(\n",
    "    in_features=len(covariates), out_features=1, output_bias=False, **mlp_config['init_params']\n",
    ")\n",
    "optimizer = tt.optim.Adam(**mlp_config['optimizer_params'])\n",
    "deepsurv = tt.Model(mlp, loss=FastCoxLoss, optimizer=optimizer)\n",
    "deepsurv_params = count_parameters(mlp)\n",
    "# Convert to PyTorch tensors\n",
    "X_test = torch.tensor(df_test[covariates].values).double()\n",
    "y_test = torch.tensor(df_test[[duration_col, event_col]].values).double()\n",
    "\n",
    "# Training\n",
    "if mlp_config['early_stopping']:\n",
    "    train, val = train_test_split(df_train, test_size=0.2, random_state=42, stratify=df_train['event'])\n",
    "    X_val = torch.tensor(val[covariates].values).double()\n",
    "    y_val = torch.tensor(val[[duration_col, event_col]].values).double()\n",
    "    X_train = torch.tensor(train[covariates].values).double()\n",
    "    y_train = torch.tensor(train[[duration_col, event_col]].values).double()\n",
    "    log = deepsurv.fit(\n",
    "        X_train, y_train, batch_size=len(X_train), val_data=(X_val, y_val), epochs=mlp_config['epochs'], verbose=False,\n",
    "        metrics={'cindex': mlp_cindex_metric_fn}, callbacks=[tt.callbacks.EarlyStopping(patience=20)]\n",
    "    )\n",
    "else:\n",
    "    X_train = torch.tensor(df_train[covariates].values).double()\n",
    "    y_train = torch.tensor(df_train[[duration_col, event_col]].values).double()\n",
    "    log = deepsurv.fit(\n",
    "        X_train, y_train, batch_size=len(X_train), val_data=(X_test, y_test), epochs=mlp_config['epochs'], verbose=False,\n",
    "        metrics={'cindex': mlp_cindex_metric_fn}\n",
    "    )\n",
    "    \n",
    "cindex_mlp = bootstrap_metric(mlp_cindex, df_test, N=100)['formatted']\n",
    "print(f\"MLP C-Index: {cindex_mlp}\")\n",
    "#plot residuals\n",
    "x1_vals = X_test[:, 0].numpy()\n",
    "x2_vals = X_test[:, 1].numpy()\n",
    "test_lph_vals = sim_config['log_partial_hazard'](x1_vals, x2_vals, *df_test[covariates[2:]].values.T)\n",
    "pred_lph_vals = deepsurv.predict(X_test).squeeze().detach().cpu().numpy()\n",
    "fig = plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this study (perhaps due to its difficulty), the hyperparameter search yielded early_stopping=True - hence we need to split the training set into a train and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# CoxKAN\n",
    "ckan = CoxKAN(seed=42, **config['init_params'])\n",
    "\n",
    "# Train/Val split for early stopping\n",
    "train, val = train_test_split(df_train, test_size=0.2, random_state=42, stratify=df_train['event'])\n",
    "\n",
    "log = ckan.train(train, val, duration_col, event_col, **config['train_params'])\n",
    "\n",
    "cindex_pre = bootstrap_metric(ckan.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Pre-symbolic: {cindex_pre}\")\n",
    "\n",
    "# Save\n",
    "ckan.save_ckpt(f'checkpoints/{exp_name}/model.pt')\n",
    "fig = log.plot()\n",
    "fig.savefig(f'checkpoints/{exp_name}/evolution.png')\n",
    "fig = ckan.plot(beta=20, in_vars=[r'$x_1$', r'$x_2$', r'$x_3$', r'$x_4$', r'$\\epsilon_1$', r'$\\epsilon_2$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_pre.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another benefit of using a validation set, is that we can use it to select a more optimal pruning threshold:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# search for pruning thresholds\n",
    "pruning_thresholds = np.linspace(0, 0.05, 20)\n",
    "pruning_thresholds[0] = config['prune_threshold']\n",
    "cindices = []\n",
    "for threshold in pruning_thresholds:\n",
    "    ckan_ = CoxKAN(seed=42, **config['init_params'])\n",
    "    ckan_.load_ckpt(f'checkpoints/{exp_name}/model.pt', verbose=False)\n",
    "    _ = ckan_.predict(df_test) # important forward pass after loading a model\n",
    "    \n",
    "    prunable = True\n",
    "    for l in range(ckan_.depth):\n",
    "        if not (ckan_.acts_scale[l] > threshold).any():\n",
    "            prunable = False\n",
    "            break\n",
    "        \n",
    "    ckan_ = ckan_.prune_nodes(threshold)\n",
    "    if 0 in ckan_.width: prunable = False\n",
    "    if not prunable:\n",
    "        if threshold == config['prune_threshold']: \n",
    "            cindices.append(0)\n",
    "            continue\n",
    "        else: break\n",
    "\n",
    "    _ = ckan_.predict(df_test) # important forward pass\n",
    "    ckan_.prune_edges(threshold, verbose=False)\n",
    "    cindices.append(ckan_.cindex(val))\n",
    "    print(f'Pruning threshold: {threshold:.2f}, C-Index (Val): {cindices[-1]:.6f}')\n",
    "best_threshold = pruning_thresholds[np.argmax(cindices)]\n",
    "if np.max(cindices) < 0.51: best_threshold = 0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Pruning\n",
    "_ = ckan.predict(df_test)\n",
    "ckan = ckan.prune_nodes(best_threshold)\n",
    "_ = ckan.predict(df_test)\n",
    "ckan.prune_edges(best_threshold, verbose=True)\n",
    "fig = ckan.plot(beta=40, in_vars=[r'$x_1$', r'$x_2$', r'$x_3$', r'$x_4$', r'$\\epsilon_1$', r'$\\epsilon_2$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_pruned.png')\n",
    "cindex_pruned = bootstrap_metric(ckan.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Pruned: {cindex_pruned}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We examine these activations and fix them accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "r2 = ckan.fix_symbolic(0, 0, 1, 'x^2', verbose=False)\n",
    "print(f\"Activation (0,0,1): x^2 fits with R^2: {r2.item()}\")\n",
    "\n",
    "r2 = ckan.fix_symbolic(0, 1, 1, 'x^2', verbose=False)\n",
    "print(f\"Activation (0,1,1): x^2 fits with R^2: {r2.item()}\")\n",
    "\n",
    "r2 = ckan.fix_symbolic(0, 2, 1, 'x^2', verbose=False)\n",
    "print(f\"Activation (0,2,1): x^2 fits with R^2: {r2.item()}\")\n",
    "\n",
    "r2 = ckan.fix_symbolic(0, 3, 1, 'x^2', verbose=False)\n",
    "print(f\"Activation (0,3,1): x^2 fits with R^2: {r2.item()}\")\n",
    "\n",
    "r2 = ckan.fix_symbolic(0, 0, 2, 'x', verbose=False)\n",
    "print(f\"Activation (0,0,2): x fits with R^2: {r2.item()}\")\n",
    "                       \n",
    "r2 = ckan.fix_symbolic(0, 1, 2, 'x', verbose=False)\n",
    "print(f\"Activation (0,1,2): x fits with R^2: {r2.item()}\")\n",
    "\n",
    "r2 = ckan.fix_symbolic(0, 2, 0, 'x', verbose=False)\n",
    "print(f\"Activation (0,2,0): x fits with R^2: {r2.item()}\")\n",
    "                       \n",
    "r2 = ckan.fix_symbolic(0, 3, 0, 'x', verbose=False)\n",
    "print(f\"Activation (0,3,0): x fits with R^2: {r2.item()}\")\n",
    "\n",
    "r2 = ckan.fix_symbolic(1, 0, 0, 'x^2', verbose=False)\n",
    "print(f\"Activation (1,0,0): x^2 fits with R^2: {r2.item()}\")\n",
    "\n",
    "r2 = ckan.fix_symbolic(1, 1, 0, 'x', verbose=False)\n",
    "print(f\"Activation (1,1,0): x^2 fits with R^2: {r2.item()}\")\n",
    "\n",
    "r2 = ckan.fix_symbolic(1, 2, 0, 'x^2', verbose=False)\n",
    "print(f\"Activation (1,2,0): x^2 fits with R^2: {r2.item()}\")\n",
    "\n",
    "r2 = ckan.fix_symbolic(2, 0, 0, 'sqrt', verbose=False)\n",
    "print(f\"Activation (2,0,0): sqrt fits with R^2: {r2.item()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The high $R^2$ in each case verifies that these functions have been learned."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "formula = ckan.symbolic_formula()[0][0]\n",
    "print(formula)\n",
    "\n",
    "#plot residuals in ckan\n",
    "x1_vals = df_test['x1'].values\n",
    "x2_vals = df_test['x2'].values\n",
    "test_lph_vals = sim_config['log_partial_hazard'](x1_vals, x2_vals, *df_test[covariates[2:]].values.T)\n",
    "pred_lph_vals = ckan.predict(df_test)\n",
    "fig = plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals)\n",
    "\n",
    "\n",
    "fig = ckan.plot(beta=40, in_vars=[r'$x_1$', r'$x_2$', r'$x_3$', r'$x_4$', r'$\\epsilon_1$', r'$\\epsilon_2$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_symbolic.png')\n",
    "cindex_symbolic = bootstrap_metric(ckan.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Symbolic: {cindex_symbolic}\")\n",
    "\n",
    "results = {\n",
    "    'cindex_true': cindex_true,\n",
    "    'cindex_cph': cindex_cph,\n",
    "    'cindex_pre': cindex_pre,\n",
    "    'cindex_pruned': cindex_pruned,\n",
    "    'cindex_symbolic': cindex_symbolic,\n",
    "    'coxkan_formula': formula,\n",
    "    'coxph_formula': formula_cph,\n",
    "}\n",
    "\n",
    "with open(f'checkpoints/{exp_name}/results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "formula"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The affine parameters are not quite right. However, if we take some liberal approximations, we see that it has captured the true expression:\n",
    "\n",
    "$ 3.97 \\sqrt{0.96*(0.06 - x_2)^2 + 0.94*(0.09 - x_1)^2 + (-x_3 - 0.04)^2 + 0.79*(-x_4 - 0.04)^2 - 0.5*(-0.97*x_1 - x_2 + 0.14)^2 - 0.67*(-x_3 - 0.71*x_4 - 0.06)^2 + 0.56} $\n",
    "\n",
    "$ \\approx 4 \\sqrt{x_2^2 + x_1^2 + x_3^2 + x_4^2 - \\frac{1}{2}(x_1 + x_2)^2 - \\frac{1}{2}(x_3 + x_4)^2} $\n",
    "\n",
    "$ = 2 \\sqrt{2x_1^2 + 2x_2^2 + 2x_3^2 + 2x_4^2 - (x_1 + x_2)^2 - (x_3 + x_4)^2} $\n",
    "\n",
    "$ = 2 \\sqrt{x_1^2 + x_2^2 - 2x_1x_2 + x_3^2 + x_4^2 - 2x_3x_4}$\n",
    "\n",
    "$ = 2 \\sqrt{(x_1 - x_2)^2 + (x_3 - x_4)^2}$\n",
    "\n",
    "Obviously, in the case of a real dataset, we would not be able to make these reckless approximations, nor would we necessarily go through spotting all these activations as their 'true' symbolic counterparts. In the next example, we will see an example where we instead just call `auto_symbolic` rather than recognising activations by eye. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intentionally difficult dataset\n",
    "\n",
    "Next we use an expression for the log-partial hazard which is intentionally difficult to capture.\n",
    "\n",
    "$$\\theta(\\mathbf{x}) = \\tanh(5(\\log(x_1) + |x_2|))$$\n",
    "\n",
    "The intuitition behind this choice is that\n",
    "- $\\tanh(5z)$ has a very shallow gradient in much of its domain, hence there will not be much of a training signal when comparing subjects in these regions.\n",
    "- $|x_2|$ is non-smooth. KAN activations use B-Splines which are necessarily smooth - thus this activation is likely to be difficult to learn. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "exp_name = \"sim_difficult\"\n",
    "sim_name = \"difficult\"\n",
    "\n",
    "# load configs\n",
    "with open(f'./configs/simulation/{sim_name}.yml', 'r') as file:\n",
    "    sim_config = yaml.safe_load(file)\n",
    "    sim_config['true_expr'] =  sim_config['log_partial_hazard'].split(': ')[-1] # log partial hazard expression\n",
    "    sim_config['log_partial_hazard'] = eval(sim_config['log_partial_hazard']) # convert to function\n",
    "\n",
    "with open(f'configs/coxkan/{exp_name}.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# data already generated (from sweep.py)\n",
    "df_train = pd.read_csv(f'./data/{exp_name}_train.csv')\n",
    "df_test = pd.read_csv(f'./data/{exp_name}_test.csv')\n",
    "duration_col, event_col, covariates = 'duration', 'event', df_train.columns[:-2]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# C-Index of true log partial hazard expression\n",
    "cindex_true = bootstrap_metric(true_cindex, df_test, N=100)['formatted']\n",
    "\n",
    "print(f\"True log partial hazard: {sim_config['true_expr']}\")\n",
    "print(f\"True C-Index: {cindex_true}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CoxPH\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df_train, duration_col=duration_col, event_col=event_col)\n",
    "cindex_cph = bootstrap_metric(cph_cindex, df_test, N=100)['formatted']\n",
    "formula_cph = cph_formula(cph)\n",
    "print(f\"CoxPH Expression: {formula_cph}\")\n",
    "print(f\"CoxPH C-Index: {cindex_cph}\")\n",
    "\n",
    "#plot residuals\n",
    "x1_vals = df_test['x1'].values\n",
    "x2_vals = df_test['x2'].values\n",
    "test_lph_vals = sim_config['log_partial_hazard'](x1_vals, x2_vals, *df_test[covariates[2:]].values.T)\n",
    "pred_lph_vals = cph.predict_partial_hazard(df_test)\n",
    "fig = plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals)\n",
    "\n",
    "# do same for CoxPH with regularization\n",
    "cph_reg = CoxPHFitter(penalizer=0.5, l1_ratio=1)\n",
    "cph_reg.fit(df_train, duration_col=duration_col, event_col=event_col)\n",
    "cindex_cph_reg = bootstrap_metric(cph_reg_cindex, df_test, N=100)['formatted']\n",
    "formula_cph_reg = cph_formula(cph_reg)\n",
    "print(f\"CoxPH (Reg) Expression: {formula_cph_reg}\")\n",
    "print(f\"CoxPH (Reg) C-Index: {cindex_cph_reg}\")\n",
    "#plot residuals\n",
    "test_lph_vals = sim_config['log_partial_hazard'](x1_vals, x2_vals, *df_test[covariates[2:]].values.T)\n",
    "pred_lph_vals = cph_reg.predict_partial_hazard(df_test)\n",
    "fig = plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# train DeepSurv on same task\n",
    "import torchtuples as tt\n",
    "from coxkan.utils import FastCoxLoss, count_parameters, bootstrap_metric, set_seed, SYMBOLIC_LIB\n",
    "import torch\n",
    "\n",
    "with open(f'configs/mlp/sim_difficult.yml', 'r') as f:\n",
    "    mlp_config = yaml.safe_load(f)\n",
    "mlp = tt.practical.MLPVanilla(\n",
    "    in_features=len(covariates), out_features=1, output_bias=False, **mlp_config['init_params']\n",
    ")\n",
    "optimizer = tt.optim.Adam(**mlp_config['optimizer_params'])\n",
    "deepsurv = tt.Model(mlp, loss=FastCoxLoss, optimizer=optimizer)\n",
    "deepsurv_params = count_parameters(mlp)\n",
    "# Convert to PyTorch tensors\n",
    "X_test = torch.tensor(df_test[covariates].values).double()\n",
    "y_test = torch.tensor(df_test[[duration_col, event_col]].values).double()\n",
    "\n",
    "# Training\n",
    "if mlp_config['early_stopping']:\n",
    "    train, val = train_test_split(df_train, test_size=0.2, random_state=42, stratify=df_train['event'])\n",
    "    X_val = torch.tensor(val[covariates].values).double()\n",
    "    y_val = torch.tensor(val[[duration_col, event_col]].values).double()\n",
    "    X_train = torch.tensor(train[covariates].values).double()\n",
    "    y_train = torch.tensor(train[[duration_col, event_col]].values).double()\n",
    "    log = deepsurv.fit(\n",
    "        X_train, y_train, batch_size=len(X_train), val_data=(X_val, y_val), epochs=mlp_config['epochs'], verbose=False,\n",
    "        metrics={'cindex': mlp_cindex_metric_fn}, callbacks=[tt.callbacks.EarlyStopping(patience=20)]\n",
    "    )\n",
    "else:\n",
    "    X_train = torch.tensor(df_train[covariates].values).double()\n",
    "    y_train = torch.tensor(df_train[[duration_col, event_col]].values).double()\n",
    "    log = deepsurv.fit(\n",
    "        X_train, y_train, batch_size=len(X_train), val_data=(X_test, y_test), epochs=mlp_config['epochs'], verbose=False,\n",
    "        metrics={'cindex': mlp_cindex_metric_fn}\n",
    "    )\n",
    "    \n",
    "cindex_mlp = bootstrap_metric(mlp_cindex, df_test, N=100)['formatted']\n",
    "print(f\"MLP C-Index: {cindex_mlp}\")\n",
    "#plot residuals\n",
    "x1_vals = X_test[:, 0].numpy()\n",
    "x2_vals = X_test[:, 1].numpy()\n",
    "test_lph_vals = sim_config['log_partial_hazard'](x1_vals, x2_vals, *df_test[covariates[2:]].values.T)\n",
    "pred_lph_vals = deepsurv.predict(X_test).squeeze().detach().cpu().numpy()\n",
    "fig = plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# CoxKAN\n",
    "ckan = CoxKAN(seed=42, **config['init_params'])\n",
    "\n",
    "log = ckan.train(df_train, df_test, duration_col, event_col, **config['train_params'])\n",
    "\n",
    "cindex_pre = bootstrap_metric(ckan.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Pre-symbolic: {cindex_pre}\")\n",
    "\n",
    "# Save\n",
    "ckan.save_ckpt(f'checkpoints/{exp_name}/model.pt')\n",
    "fig = log.plot()\n",
    "fig.savefig(f'checkpoints/{exp_name}/evolution.png')\n",
    "fig = ckan.plot(beta=10, in_vars=[r'$x_1$', r'$x_2$', r'$\\epsilon_1$', r'$\\epsilon_2$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_pre.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Pruning\n",
    "ckan = ckan.prune_nodes(config['prune_threshold'])\n",
    "ckan.prune_edges(config['prune_threshold'], verbose=True)\n",
    "fig = ckan.plot(beta=10, in_vars=[r'$x_1$', r'$x_2$', r'$\\epsilon_1$', r'$\\epsilon_2$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_pruned.png')\n",
    "cindex_pruned = bootstrap_metric(ckan.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Pruned: {cindex_pruned}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the activations do seem to be close to their 'true' counterparts, we would not naturally recognise them by eye. As we expected, the model appears to have had issues with the `tanh` (parts of the domain that should be flat are not bumpy) and `abs` (too smooth at the bottom). \n",
    "\n",
    "Hence, instead of recognising activations by eye, we simply call `auto_symbolic`. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# _ = ckan.auto_symbolic(only_interpretable_funcs=True, verbose=True)\n",
    "_ = ckan.auto_symbolic(only_interpretable_funcs=False, verbose=True)\n",
    "\n",
    "_ = ckan.predict(df_test)\n",
    "fig = ckan.plot(beta=10, in_vars=[r'$x_1$', r'$x_2$', r'$\\epsilon_1$', r'$\\epsilon_2$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_symbolic.png')\n",
    "cindex_symbolic = bootstrap_metric(ckan.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Symbolic: {cindex_symbolic}\")\n",
    "formula = ckan.symbolic_formula()[0][0]\n",
    "print(formula)\n",
    "\n",
    "#plot residuals in ckan\n",
    "x1_vals = df_test['x1'].values\n",
    "x2_vals = df_test['x2'].values\n",
    "test_lph_vals = sim_config['log_partial_hazard'](x1_vals, x2_vals, *df_test[covariates[2:]].values.T)\n",
    "pred_lph_vals = ckan.predict(df_test)\n",
    "fig = plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, the `tanh` activation was recovered, and the symbolic fitting actually smoothed out some of the noisy bumps, yielding a better result. Unforunately, the other activations were not recovered. \n",
    "\n",
    "However, the C-Index is very close to that of the true expression, suggesting that our expression is a close approximation in the relevant domain. We now plot the true and predicted expressions:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "\n",
    "x1_range=(0.1, 1)\n",
    "x2_range=(-1, 1)\n",
    "\n",
    "# create grid of x1 and x2 values\n",
    "x1 = np.linspace(*x1_range, 100)\n",
    "x2 = np.linspace(*x2_range, 100)\n",
    "X = np.meshgrid(x1, x2)\n",
    "X = np.array(X).reshape(2, -1).T\n",
    "X = torch.tensor(X, dtype=torch.float64)\n",
    "\n",
    "# add noise\n",
    "X = torch.cat([X, torch.zeros_like(X)[:, :2]], dim=1)\n",
    "\n",
    "# get the predicted log partial hazard\n",
    "lph_true = sim_config['log_partial_hazard'](X[:,0], X[:,1], *X[:,2:].T)\n",
    "\n",
    "with torch.no_grad():\n",
    "    lph_pred = ckan(X)\n",
    "lph_pred = lph_pred.detach().numpy().flatten()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# plot the true log partial hazard\n",
    "levels = np.linspace(lph_true.min(), lph_true.max(), 100)\n",
    "contour = axes[0].tricontourf(X[:,0], X[:,1], lph_true, levels=levels, cmap='coolwarm')\n",
    "axes[0].set_xlabel(r'$x_1$', fontsize=14)\n",
    "axes[0].set_ylabel(r'$x_2$', fontsize=14)\n",
    "axes[0].set_xticks(x1_range)\n",
    "axes[0].set_yticks(x2_range)\n",
    "\n",
    "# plot the predicted log partial hazard\n",
    "levels = np.linspace(lph_pred.min(), lph_pred.max(), 100)\n",
    "contour = axes[1].tricontourf(X[:,0], X[:,1], lph_pred, levels=levels, cmap='coolwarm')\n",
    "axes[1].set_xlabel(r'$x_1$', fontsize=14)\n",
    "axes[1].set_ylabel(r'$x_2$', fontsize=14)\n",
    "axes[1].set_xticks(x1_range)\n",
    "axes[1].set_yticks(x2_range)\n",
    "\n",
    "axes[0].text(0.02, 1.05, r'(a) True $\\theta(\\mathbf{x})$', fontsize=17, transform=axes[0].transAxes)\n",
    "axes[1].text(0.02, 1.05, r'(b) CoxKAN Symbolic $\\hat{\\theta}(\\mathbf{x})$', fontsize=17, transform=axes[1].transAxes)\n",
    "\n",
    "fig.savefig(f'checkpoints/{exp_name}/lph_surfaces.png')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that indeed, the predicted expression is a very close approximation to the truth. \n",
    "\n",
    "I argue that CoxKAN still has the properties of high performance and interpretability in this case."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "results = {\n",
    "    'cindex_true': cindex_true,\n",
    "    'cindex_cph': cindex_cph,\n",
    "    'cindex_pre': cindex_pre,\n",
    "    'cindex_pruned': cindex_pruned,\n",
    "    'cindex_symbolic': cindex_symbolic,\n",
    "    'coxkan_formula': formula,\n",
    "    'coxph_formula': formula_cph,\n",
    "}\n",
    "\n",
    "with open(f'checkpoints/{exp_name}/results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Linear"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import copy\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pickle\n",
    "import argparse\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "from coxkan import CoxKAN\n",
    "from coxkan.utils import bootstrap_metric, set_seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = set_seed(42)\n",
    "\n",
    "### Reusable functions for the notebook\n",
    "\n",
    "def true_cindex(df):\n",
    "    global sim_config, duration_col, event_col, covariates\n",
    "    lph = sim_config['log_partial_hazard'](**df[covariates])\n",
    "    return concordance_index(df[duration_col], -lph, df[event_col])\n",
    "\n",
    "def cph_cindex(df):\n",
    "    global cph\n",
    "    return cph.score(df, scoring_method='concordance_index')\n",
    "\n",
    "def cph_reg_cindex(df):\n",
    "    global cph_reg\n",
    "    return cph_reg.score(df, scoring_method='concordance_index')\n",
    "\n",
    "def cph_formula(cph):\n",
    "    coefficients = cph.params_\n",
    "    terms = []\n",
    "    for covariate, coefficient in coefficients.items():\n",
    "        term = f\"{coefficient:.4f} * {covariate}\"\n",
    "        terms.append(term)\n",
    "    expression = \" + \".join(terms)\n",
    "    return expression\n",
    "\n",
    "def cph_reg_formula(cph_reg):\n",
    "    print(cph_reg.params_)\n",
    "    coefficients = cph_reg.params_\n",
    "    terms = []\n",
    "    for covariate, coefficient in coefficients.items():\n",
    "        term = f\"{coefficient:.4f} * {covariate}\"\n",
    "        terms.append(term)\n",
    "    expression = \" + \".join(terms)\n",
    "    return expression\n",
    "exp_name = \"sim_reviewer_1_2\"\n",
    "sim_name = \"reviewer_1_2\"\n",
    "\n",
    "### load configs\n",
    "with open(f'./configs/simulation/{sim_name}.yml', 'r') as file:\n",
    "    sim_config = yaml.safe_load(file)\n",
    "    sim_config['true_expr'] =  sim_config['log_partial_hazard'].split(': ')[-1] # log partial hazard expression\n",
    "    sim_config['log_partial_hazard'] = eval(sim_config['log_partial_hazard']) # convert to function\n",
    "\n",
    "# (config from hyperparameter search)\n",
    "with open(f'configs/coxkan/{exp_name}.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# data already generated (from sweep.py)\n",
    "df_train = pd.read_csv(f'./data/{exp_name}_train.csv')\n",
    "df_test = pd.read_csv(f'./data/{exp_name}_test.csv')\n",
    "duration_col, event_col, covariates = 'duration', 'event', df_train.columns[:-2]\n",
    "# C-Index of true log partial hazard expression\n",
    "cindex_true = bootstrap_metric(true_cindex, df_test, N=100)['formatted']\n",
    "\n",
    "print(f\"True log partial hazard: {sim_config['true_expr']}\")\n",
    "print(f\"True C-Index: {cindex_true}\")\n",
    "# CoxPH\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df_train, duration_col=duration_col, event_col=event_col)\n",
    "cindex_cph = bootstrap_metric(cph_cindex, df_test, N=100)['formatted']\n",
    "formula_cph = cph_formula(cph)\n",
    "print(f\"CoxPH Expression: {formula_cph}\")\n",
    "print(f\"CoxPH C-Index: {cindex_cph}\")\n",
    "\n",
    "#CoxPH with Lasso\n",
    "cph_reg = CoxPHFitter(penalizer=0.5,l1_ratio=1)\n",
    "cph_reg.fit(df_train, duration_col=duration_col, event_col=event_col)\n",
    "cindex_cph_reg = bootstrap_metric(cph_reg_cindex, df_test, N=100)['formatted']\n",
    "formula_cph_reg = cph_reg_formula(cph_reg)\n",
    "print(f\"CoxPH with Lasso Expression: {formula_cph_reg}\")\n",
    "print(f\"CoxPH with Lasso C-Index: {cindex_cph_reg}\")\n",
    "\n",
    "test_lph = sim_config['log_partial_hazard'](df_test['x1'], df_test['x2'], df_test['x3'], df_test['x4'])\n",
    "pred_lph = cph_reg.predict_partial_hazard(df_test)\n",
    "x1_vals = df_test['x1'].values\n",
    "x2_vals = df_test['x2'].values\n",
    "fig = plot_residuals(test_lph,pred_lph,x1_vals,x2_vals)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CoxKAN\n",
    "ckan_trained = CoxKAN(seed=42, **config['init_params'])\n",
    "# Train/Val split for early stopping\n",
    "train, val = train_test_split(df_train, test_size=0.2, random_state=42, stratify=df_train['event'])\n",
    "log = ckan_trained.train(train, val, duration_col, event_col, **config['train_params'])\n",
    "\n",
    "cindex_pre = bootstrap_metric(ckan_trained.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Pre-symbolic: {cindex_pre}\")\n",
    "\n",
    "# Save\n",
    "ckan_trained.save_ckpt(f'checkpoints/{exp_name}/model.pt')\n",
    "fig = log.plot()\n",
    "fig.savefig(f'checkpoints/{exp_name}/evolution.png')\n",
    "fig = ckan_trained.plot(beta=10, in_vars=[r'$x_1$', r'$x_2$', r'$x_3$', r'$x_4$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_pre.png')\n",
    "\n",
    "# search for pruning thresholds\n",
    "pruning_thresholds = np.linspace(0, 0.05, 20)\n",
    "pruning_thresholds[0] = config['prune_threshold']\n",
    "cindices = []\n",
    "for threshold in pruning_thresholds:\n",
    "    ckan_ = CoxKAN(seed=42, **config['init_params'])\n",
    "    ckan_.load_ckpt(f'checkpoints/{exp_name}/model.pt', verbose=False)\n",
    "    _ = ckan_.predict(df_test) # important forward pass after loading a model\n",
    "    \n",
    "    prunable = True\n",
    "    for l in range(ckan_.depth):\n",
    "        if not (ckan_.acts_scale[l] > threshold).any():\n",
    "            prunable = False\n",
    "            break\n",
    "        \n",
    "    ckan_ = ckan_.prune_nodes(threshold)\n",
    "    if 0 in ckan_.width: prunable = False\n",
    "    if not prunable:\n",
    "        if threshold == config['prune_threshold']: \n",
    "            cindices.append(0)\n",
    "            continue\n",
    "        else: break\n",
    "\n",
    "    _ = ckan_.predict(df_test) # important forward pass\n",
    "    ckan_.prune_edges(threshold, verbose=False)\n",
    "    cindices.append(ckan_.cindex(val))\n",
    "    print(f'Pruning threshold: {threshold:.2f}, C-Index (Val): {cindices[-1]:.6f}')\n",
    "best_threshold = pruning_thresholds[np.argmax(cindices)]\n",
    "if np.max(cindices) < 0.51: best_threshold = 0\n",
    "\n",
    "_ = ckan_trained.predict(df_test)\n",
    "ckan_trained = ckan_trained.prune_nodes(best_threshold)\n",
    "_ = ckan_trained.predict(df_test)\n",
    "ckan_trained.prune_edges(best_threshold, verbose=True)\n",
    "fig = ckan_trained.plot(beta=40, in_vars=[r'$x_1$', r'$x_2$', r'$x_3$', r'$x_4$', r'$\\epsilon_1$', r'$\\epsilon_2$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_pruned.png')\n",
    "cindex_pruned = bootstrap_metric(ckan_trained.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Pruned: {cindex_pruned}\")\n",
    "\n",
    "# _ = ckan_trained.auto_symbolic(only_interpretable_funcs=True, verbose=True)\n",
    "_ = ckan.auto_symbolic(only_interpretable_funcs=False, verbose=True)\n",
    "\n",
    "_ = ckan_trained.predict(df_test)\n",
    "fig = ckan_trained.plot(beta=10, in_vars=[r'$x_1$', r'$x_2$', r'$\\epsilon_1$', r'$\\epsilon_2$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_symbolic.png')\n",
    "cindex_symbolic = bootstrap_metric(ckan_trained.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Symbolic: {cindex_symbolic}\")\n",
    "formula = ckan_trained.symbolic_formula()[0][0]\n",
    "print(formula)\n",
    "\n",
    "\n",
    "_ = ckan_trained.predict(df_test)\n",
    "fig = ckan_trained.plot(beta=10, in_vars=[r'$x_1$', r'$x_2$', r'$x_3$', r'$x_4$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_symbolic.png')\n",
    "cindex_symbolic = bootstrap_metric(ckan_trained.cindex, df_test, N=100)['formatted']\n",
    "#plot x1, x2 with survival as color in test data AND by inputting the test data into the symbolic expression\n",
    "# have it be two-plot wide subplots\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "test_x1 = df_test['x1'].values\n",
    "test_x2 = df_test['x2'].values\n",
    "test_x3 = df_test['x3'].values\n",
    "test_x4 = df_test['x4'].values\n",
    "test_surv = df_test['duration'].values\n",
    "test_lph = sim_config['log_partial_hazard'](test_x1, test_x2, test_x3, test_x4)\n",
    "print(test_lph)\n",
    "pred_lph = ckan_trained.predict(df_test)\n",
    "fig = plot_residuals(test_lph,pred_lph,test_x1,test_x2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Quadratic"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import copy\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pickle\n",
    "import argparse\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lifelines.utils import concordance_index\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "from coxkan import CoxKAN\n",
    "from coxkan.utils import bootstrap_metric, set_seed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = set_seed(42)\n",
    "\n",
    "### Reusable functions for the notebook\n",
    "\n",
    "def true_cindex(df):\n",
    "    global sim_config, duration_col, event_col, covariates\n",
    "    lph = sim_config['log_partial_hazard'](**df[covariates])\n",
    "    return concordance_index(df[duration_col], -lph, df[event_col])\n",
    "\n",
    "def cph_cindex(df):\n",
    "    global cph\n",
    "    return cph.score(df, scoring_method='concordance_index')\n",
    "\n",
    "def cph_reg_cindex(df):\n",
    "    global cph_reg\n",
    "    return cph_reg.score(df, scoring_method='concordance_index')\n",
    "\n",
    "def cph_formula(cph):\n",
    "    coefficients = cph.params_\n",
    "    terms = []\n",
    "    for covariate, coefficient in coefficients.items():\n",
    "        term = f\"{coefficient:.4f} * {covariate}\"\n",
    "        terms.append(term)\n",
    "    expression = \" + \".join(terms)\n",
    "    return expression\n",
    "\n",
    "def cph_reg_formula(cph_reg):\n",
    "    print(cph_reg.params_)\n",
    "    coefficients = cph_reg.params_\n",
    "    terms = []\n",
    "    for covariate, coefficient in coefficients.items():\n",
    "        term = f\"{coefficient:.4f} * {covariate}\"\n",
    "        terms.append(term)\n",
    "    expression = \" + \".join(terms)\n",
    "    return expression\n",
    "exp_name = \"sim_reviewer_1_3\"\n",
    "sim_name = \"reviewer_1_3\"\n",
    "\n",
    "def plot_residuals(test_lph_vals,pred_lph_vals,x1_vals,x2_vals):\n",
    "    #plot residuals in 1x2 grid vs x1 and x2\n",
    "    residuals = test_lph_vals - pred_lph_vals\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    axes[0].scatter(x1_vals, residuals, alpha=0.5)\n",
    "    #insert correlation as text\n",
    "    corr = np.corrcoef(x1_vals, residuals)[0, 1]\n",
    "    axes[0].text(0.5, 0.9, f'Correlation: {corr:.2f}', transform=axes[0].transAxes, fontsize=14)\n",
    "    axes[0].set_xlabel(r'$x_1$', fontsize=14)\n",
    "    axes[0].set_ylabel('Residuals', fontsize=14)\n",
    "    axes[0].set_title('Residuals vs $x_1$', fontsize=14)\n",
    "    axes[1].scatter(x2_vals, residuals, alpha=0.5)\n",
    "    #insert correlation as text\n",
    "    corr = np.corrcoef(x2_vals, residuals)[0, 1]\n",
    "    axes[1].text(0.5, 0.9, f'Correlation: {corr:.2f}', transform=axes[1].transAxes, fontsize=14)\n",
    "    axes[1].set_xlabel(r'$x_2$', fontsize=14)\n",
    "    axes[1].set_ylabel('Residuals', fontsize=14)\n",
    "    axes[1].set_title('Residuals vs $x_2$', fontsize=14)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "### load configs\n",
    "with open(f'./configs/simulation/{sim_name}.yml', 'r') as file:\n",
    "    sim_config = yaml.safe_load(file)\n",
    "    sim_config['true_expr'] =  sim_config['log_partial_hazard'].split(': ')[-1] # log partial hazard expression\n",
    "    sim_config['log_partial_hazard'] = eval(sim_config['log_partial_hazard']) # convert to function\n",
    "\n",
    "# (config from hyperparameter search)\n",
    "with open(f'configs/coxkan/{exp_name}.yml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# data already generated (from sweep.py)\n",
    "df_train = pd.read_csv(f'./data/{exp_name}_train.csv')\n",
    "df_test = pd.read_csv(f'./data/{exp_name}_test.csv')\n",
    "duration_col, event_col, covariates = 'duration', 'event', df_train.columns[:-2]\n",
    "# C-Index of true log partial hazard expression\n",
    "cindex_true = bootstrap_metric(true_cindex, df_test, N=100)['formatted']\n",
    "\n",
    "print(f\"True log partial hazard: {sim_config['true_expr']}\")\n",
    "print(f\"True C-Index: {cindex_true}\")\n",
    "# CoxPH\n",
    "cph = CoxPHFitter()\n",
    "cph.fit(df_train, duration_col=duration_col, event_col=event_col)\n",
    "cindex_cph = bootstrap_metric(cph_cindex, df_test, N=100)['formatted']\n",
    "formula_cph = cph_formula(cph)\n",
    "print(f\"CoxPH Expression: {formula_cph}\")\n",
    "print(f\"CoxPH C-Index: {cindex_cph}\")\n",
    "\n",
    "test_lph = sim_config['log_partial_hazard'](test_x1, test_x2, test_x3, test_x4)\n",
    "pred_lph = cph.predict_partial_hazard(df_test)\n",
    "\n",
    "x1_vals = df_test['x1'].values\n",
    "x2_vals = df_test['x2'].values\n",
    "\n",
    "fig = plot_residuals(test_lph,pred_lph,x1_vals,x2_vals)\n",
    "\n",
    "#CoxPH with Lasso\n",
    "cph_reg = CoxPHFitter(penalizer=0.5,l1_ratio=1)\n",
    "cph_reg.fit(df_train, duration_col=duration_col, event_col=event_col)\n",
    "cindex_cph_reg = bootstrap_metric(cph_reg_cindex, df_test, N=100)['formatted']\n",
    "formula_cph_reg = cph_reg_formula(cph_reg)\n",
    "print(f\"CoxPH with Lasso Expression: {formula_cph_reg}\")\n",
    "print(f\"CoxPH with Lasso C-Index: {cindex_cph_reg}\")\n",
    "\n",
    "test_lph = sim_config['log_partial_hazard'](test_x1, test_x2, test_x3, test_x4)\n",
    "pred_lph = cph_reg.predict_partial_hazard(df_test)\n",
    "\n",
    "x1_vals = df_test['x1'].values\n",
    "x2_vals = df_test['x2'].values\n",
    "\n",
    "fig = plot_residuals(test_lph,pred_lph,x1_vals,x2_vals)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# CoxKAN\n",
    "ckan_trained = CoxKAN(seed=42, **config['init_params'])\n",
    "# Train/Val split for early stopping\n",
    "train, val = train_test_split(df_train, test_size=0.2, random_state=42, stratify=df_train['event'])\n",
    "log = ckan_trained.train(train, val, duration_col, event_col, **config['train_params'])\n",
    "\n",
    "cindex_pre = bootstrap_metric(ckan_trained.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Pre-symbolic: {cindex_pre}\")\n",
    "\n",
    "# Save\n",
    "ckan_trained.save_ckpt(f'checkpoints/{exp_name}/model.pt')\n",
    "fig = log.plot()\n",
    "fig.savefig(f'checkpoints/{exp_name}/evolution.png')\n",
    "fig = ckan_trained.plot(beta=10, in_vars=[r'$x_1$', r'$x_2$', r'$x_3$', r'$x_4$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_pre.png')\n",
    "\n",
    "# search for pruning thresholds\n",
    "pruning_thresholds = np.linspace(0, 0.05, 20)\n",
    "pruning_thresholds[0] = config['prune_threshold']\n",
    "cindices = []\n",
    "for threshold in pruning_thresholds:\n",
    "    ckan_ = CoxKAN(seed=42, **config['init_params'])\n",
    "    ckan_.load_ckpt(f'checkpoints/{exp_name}/model.pt', verbose=False)\n",
    "    _ = ckan_.predict(df_test) # important forward pass after loading a model\n",
    "    \n",
    "    prunable = True\n",
    "    for l in range(ckan_.depth):\n",
    "        if not (ckan_.acts_scale[l] > threshold).any():\n",
    "            prunable = False\n",
    "            break\n",
    "        \n",
    "    ckan_ = ckan_.prune_nodes(threshold)\n",
    "    if 0 in ckan_.width: prunable = False\n",
    "    if not prunable:\n",
    "        if threshold == config['prune_threshold']: \n",
    "            cindices.append(0)\n",
    "            continue\n",
    "        else: break\n",
    "\n",
    "    _ = ckan_.predict(df_test) # important forward pass\n",
    "    ckan_.prune_edges(threshold, verbose=False)\n",
    "    cindices.append(ckan_.cindex(val))\n",
    "    print(f'Pruning threshold: {threshold:.2f}, C-Index (Val): {cindices[-1]:.6f}')\n",
    "best_threshold = pruning_thresholds[np.argmax(cindices)]\n",
    "if np.max(cindices) < 0.51: best_threshold = 0\n",
    "\n",
    "_ = ckan_trained.predict(df_test)\n",
    "ckan_trained = ckan_trained.prune_nodes(best_threshold)\n",
    "_ = ckan_trained.predict(df_test)\n",
    "ckan_trained.prune_edges(best_threshold, verbose=True)\n",
    "fig = ckan_trained.plot(beta=40, in_vars=[r'$x_1$', r'$x_2$', r'$x_3$', r'$x_4$', r'$\\epsilon_1$', r'$\\epsilon_2$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_pruned.png')\n",
    "cindex_pruned = bootstrap_metric(ckan_trained.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Pruned: {cindex_pruned}\")\n",
    "\n",
    "# _ = ckan_trained.auto_symbolic(only_interpretable_funcs=True, verbose=True)\n",
    "_ = ckan.auto_symbolic(only_interpretable_funcs=False, verbose=True)\n",
    "\n",
    "_ = ckan_trained.predict(df_test)\n",
    "fig = ckan_trained.plot(beta=10, in_vars=[r'$x_1$', r'$x_2$', r'$\\epsilon_1$', r'$\\epsilon_2$'])\n",
    "fig.savefig(f'checkpoints/{exp_name}/coxkan_symbolic.png')\n",
    "cindex_symbolic = bootstrap_metric(ckan_trained.cindex, df_test, N=100)['formatted']\n",
    "print(f\"Symbolic: {cindex_symbolic}\")\n",
    "formula = ckan_trained.symbolic_formula()[0][0]\n",
    "print(formula)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "test_x1 = df_test['x1'].values\n",
    "test_x2 = df_test['x2'].values\n",
    "test_x3 = df_test['x3'].values\n",
    "test_x4 = df_test['x4'].values\n",
    "test_surv = df_test['duration'].values\n",
    "test_lph = sim_config['log_partial_hazard'](test_x1, test_x2, test_x3, test_x4)\n",
    "print(test_lph)\n",
    "\n",
    "pred_lph = ckan_trained.predict(df_test)\n",
    "x1_vals = df_test['x1'].values\n",
    "x2_vals = df_test['x2'].values\n",
    "fig = plot_residuals(test_lph,pred_lph,x1_vals,x2_vals)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coxkan-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
